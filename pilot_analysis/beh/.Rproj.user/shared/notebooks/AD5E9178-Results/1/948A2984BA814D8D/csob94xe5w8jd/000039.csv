"0","# check out many subs"
"0","subs<-list.files(abs, pattern=""sub"")"
"0",""
"0","# delete the sub_000"
"0","subs<-subs[subs!=""sub_000""]"
"0",""
"0",""
"0","data_all<-vector()"
"0","data_all_encoding<-vector()"
"0","subs<-""sub_194"""
"0","for(sub in subs){"
"0","  "
"0","  dominant_eye<-""right"""
"0","  "
"0","  file_location<-(paste0(abs, sub, ""/beh/""))"
"0","  "
"0","  et_location<-(paste0(abs, sub, ""/et/""))"
"0","  "
"0","  all_files<-list.files(file_location)"
"0","  "
"0","  enc_file<-all_files[grep(""test|encoding"", all_files)]"
"0","  "
"0","  rec_file<-all_files[grep(""recognition|retrieval"", all_files)]"
"0","  "
"0","  data_recog<-read.csv(paste0(file_location,rec_file))"
"0","  "
"0","  data_encoding<-read.csv(paste0(file_location,enc_file))"
"0","  "
"0","  # get only the trials"
"0","  data_encoding<-data_encoding[!is.na(data_encoding$radians),]"
"0","  "
"0","  sub_n<-as.numeric(substr(sub, 5,7))"
"0","  "
"0","  data_et<-read.csv(paste0(et_location, ""sub-"",  sub_n, ""_eye-"", dominant_eye, "
"0","                           ""_last-fixation_et.csv""))"
"0","  "
"0","  # attach to the encoding dataset"
"0","  data_encoding_et<-cbind(data_encoding, data_et)"
"0","  "
"0","  # get the angle given x and y coordinates"
"0","  # the x coordinate is the adjacent while the y is the opposite"
"0","  # tan(angle) = opposite (y) / adjacent (x) "
"0","  # angle = tan-1(opposite/adjacent)"
"0",""
"0","  # get the angle (in radians) and convert it into degrees"
"0","  # however, the opposite is given in + and -"
"0","  "
"0","  new_y<-ifelse(data_encoding_et$y<=540, (540-data_encoding_et$y), -(data_encoding_et$y-540 ))"
"0","  new_x<-ifelse(data_encoding_et$x<=960, -(960-data_encoding_et$x), (data_encoding_et$x-960))"
"0",""
"0","  # get the quadrant"
"0","  quadrant<-NA"
"0","  tanx<-NA"
"0","  x_rad<-NA"
"0","  x_deg<-NA"
"0","  for (n in 1:length(new_y)){"
"0","    if (!is.na(new_y[n])){"
"0","  if (new_x[n]>0 & new_y[n]>0){"
"0","    quadrant[n]<-1"
"0","    tanx[n]<-(new_y[n])/(new_x[n])"
"0","    x_rad[n]<-atan(tanx[n])"
"0","    x_deg[n]<-x_rad[n]*180/pi"
"0","  }else if(new_y[n]>0 & new_x[n]<0){"
"0","    quadrant[n]<-2"
"0","    tanx[n]<-(new_y[n])/(new_x[n])"
"0","    x_rad[n]<-atan(tanx[n])"
"0","    x_deg[n]<-(x_rad[n]*180/pi)+180"
"0","  } else if(new_y[n]<0 & new_x[n]<0){"
"0","  quadrant[n]<-3"
"0","  tanx[n]<-(new_y[n])/(new_x[n])"
"0","  x_rad[n]<-atan(tanx[n])"
"0","  x_deg[n]<-(x_rad[n]*180/pi)+180"
"0","  } else{"
"0","  quadrant[n]<-4"
"0","  tanx[n]<-(new_y[n])/(new_x[n])"
"0","  x_rad[n]<-atan(tanx[n])"
"0","  x_deg[n]<-(x_rad[n]*180/pi)+360"
"0","  }"
"0","    }"
"0","  }"
"0","  "
"0","  data_encoding_et$fixations<-x_deg"
"0","  "
"0","  # calculate distance"
"0","  data_encoding_et$fixation_error<-NA"
"0","for (j in 1:nrow(data_encoding_et)){"
"0","  # location center in degrees"
"0","  presented<-as.numeric(data_encoding_et$degrees[j])"
"0","  # fixation"
"0","  fixation<-data_encoding_et$fixations[j]"
"0","  #radCent<-center*3.14/180"
"0","  firstdiff<- abs(presented-fixation)"
"0","  "
"0","  max_deg<-max(presented,fixation)"
"0","  min_deg<-min(presented, fixation)"
"0","  "
"0","  seconddiff<-abs(min_deg +(360-max_deg))"
"0","  data_encoding_et$fixation_error[j]<-min((firstdiff), (seconddiff))"
"0","}"
"0","  "
"0","  "
"0","  "
"0","  # remove the duplicates in the recognition file"
"0","  images<-as.character(unique(data_recog$stimulus))"
"0","  "
"0","  # remove empty values"
"0","  images<-images[nchar(images)>1]"
"0","  "
"0","  # create two datasets, one for recognition (first occurrence), one for location"
"0","  # (second occurrence)"
"0","  recog<-list()"
"0","  #locat<-list()"
"0","  for (im in 1:length(images)){"
"0","    # subset the image"
"0","    curr_im<-data_recog[data_recog$stimulus==images[im],]"
"0","    "
"0","    max<-nrow(curr_im)"
"0","    "
"0","    recog[[im]]<-curr_im[1,]"
"0","    # locat[[im]]<-curr_im[max,]"
"0","    "
"0","    "
"0","  }"
"0","  "
"0","  data_rec<-do.call(rbind, recog)"
"0","  #data_loc<-do.call(rbind, locat)"
"0",""
"0","  "
"0","  # create accuracy"
"0"," if (sub==""sub_194""){"
"0","   data_rec$recog_acc<-NA"
"0","  for (n in 1:nrow(data_rec)){"
"0","    if (data_rec$old_new[n] == ""old""){"
"0","        if (data_rec$conf_resp.keys[n]>=4){"
"0","        data_rec$recog_acc[n]<- 1 }else{   data_rec$recog_acc[n]<- 0}"
"0","    }else if(data_rec$old_new[n] == ""new""){"
"0","         if (data_rec$conf_resp.keys[n]<4){"
"0","         data_rec$recog_acc[n]<- 1 }else{   data_rec$recog_acc[n]<- 0}"
"0","    }"
"0","  }"
"0","  "
"0"," }else{"
"0","  "
"0","  if (sub_n%%2==0){"
"0","    old_response<-""left"""
"0","  }else{"
"0","    old_response<-""right"""
"0","  }"
"0","  "
"0","  data_rec$recog_acc<-ifelse(data_rec$old_new==""old"" &"
"0","                               data_rec$recog_resp.keys==old_response, 1, 0)"
"0"," }"
"0","  # save it"
"0","  write.csv(data_rec, paste0(output,""beh/"", sub, ""_recognition_cleaned.csv""))"
"0","  "
"0","  data_all<-rbind(data_all, data_rec)"
"0","  "
"0","  data_all_encoding<-rbind(data_all_encoding, data_encoding_et)"
"0","  "
"0","}"
"2","Error in `$<-.data.frame`(`*tmp*`, ""fixations"", value = c(NA, 80.1454777242429,  : 
  replacement has 199 rows, data has 200
"
